{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day11 Notes.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPnXxvLxeXdM6f//vTUSztE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merriekay/CS167Code/blob/main/Day11_Notes_f21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8ZtDAuV1pkR"
      },
      "source": [
        "# Day 11 Notes: Random Forests\n",
        "\n",
        "Using a new dataset, this set of notes walks through how to use Random Forests in sklearn, and also demonstrates tuning different parameters related to Random Forests. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "Lr2RqT5F1llk",
        "outputId": "86433e66-2ef8-4254-acdf-61bcd31da002"
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive')\n",
        "data= pd.read_csv('/content/drive/MyDrive/CS167_S21/CS167_datasets/breast-cancer-wisconsin-data.csv')\n",
        "data.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0    842302         M  ...                  0.11890          NaN\n",
              "1    842517         M  ...                  0.08902          NaN\n",
              "2  84300903         M  ...                  0.08758          NaN\n",
              "3  84348301         M  ...                  0.17300          NaN\n",
              "4  84358402         M  ...                  0.07678          NaN\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45PkceoVyFDL",
        "outputId": "5c2d6432-1e6c-453a-982a-ec7355f59c96"
      },
      "source": [
        "# Notice that the 'Unnamed: 32' column is full of NaN... we need to get rid of it. \n",
        "data.drop('Unnamed: 32', inplace=True, axis=1)\n",
        "data.isna().any()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                         False\n",
              "diagnosis                  False\n",
              "radius_mean                False\n",
              "texture_mean               False\n",
              "perimeter_mean             False\n",
              "area_mean                  False\n",
              "smoothness_mean            False\n",
              "compactness_mean           False\n",
              "concavity_mean             False\n",
              "concave points_mean        False\n",
              "symmetry_mean              False\n",
              "fractal_dimension_mean     False\n",
              "radius_se                  False\n",
              "texture_se                 False\n",
              "perimeter_se               False\n",
              "area_se                    False\n",
              "smoothness_se              False\n",
              "compactness_se             False\n",
              "concavity_se               False\n",
              "concave points_se          False\n",
              "symmetry_se                False\n",
              "fractal_dimension_se       False\n",
              "radius_worst               False\n",
              "texture_worst              False\n",
              "perimeter_worst            False\n",
              "area_worst                 False\n",
              "smoothness_worst           False\n",
              "compactness_worst          False\n",
              "concavity_worst            False\n",
              "concave points_worst       False\n",
              "symmetry_worst             False\n",
              "fractal_dimension_worst    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUCdUIbv15kX"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "target = \"diagnosis\"\n",
        "predictors = data.columns.drop(target) #gets all of the columns except the target\n",
        "\n",
        "train_data, test_data, train_sln, test_sln = train_test_split(data[predictors], data[target], test_size = 0.2, random_state=41)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf3h23iI2m6c"
      },
      "source": [
        "from sklearn import tree\n",
        "from sklearn import metrics\n",
        "\n",
        "# Let's use a single tree for comparison\n",
        "# a default Decision Tree Classifier\n",
        "\n",
        "dt = tree.DecisionTreeClassifier()\n",
        "dt.fit(train_data,train_sln)\n",
        "predictions = dt.predict(test_data)\n",
        "\n",
        "print(\"accuracy score: \", metrics.accuracy_score(test_sln,predictions))\n",
        "vals = data[target].unique() ## possible classification values (M = malignant; B = benign)\n",
        "conf_mat = metrics.confusion_matrix(test_sln, predictions, labels=vals)\n",
        "print(pd.DataFrame(conf_mat, index = \"True \" + vals, columns = \"Predicted \" + vals))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5iXyptv3GSF"
      },
      "source": [
        "# a Random Forest Classifier\n",
        "forest = RandomForestClassifier(random_state = 0, n_estimators=100)\n",
        "forest.fit(train_data,train_sln)\n",
        "predictions = forest.predict(test_data)\n",
        "print(\"accuracy score: \", metrics.accuracy_score(test_sln,predictions))\n",
        "\n",
        "vals = data[target].unique() ## possible classification values (M = malignant; B = benign)\n",
        "conf_mat = metrics.confusion_matrix(test_sln, predictions, labels=vals)\n",
        "print(pd.DataFrame(conf_mat, index = \"True \" + vals, columns = \"Predicted \" + vals))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-hqyWEN3h1R"
      },
      "source": [
        "## Feature Importances\n",
        "Becuase we are building so many small decision trees in a random forest, we have the added benefit of being able to see what features are most commonly used as high information gain features. The code below shows how we can plot the 'Feature Importance' chart for a random forest. \n",
        "\n",
        "In this particular run, it looks like perimeter_worst was the most important feature, but there were a handful of others that were important as well. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ctkby7Ni3Zxp"
      },
      "source": [
        "# It looks like our random forest model achieved pretty good accuracy. \n",
        "# Now lets check how important each of the features was in the ensemble of models we built.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "index = range(len(predictors)) #creates a list of numbers the right size to use as the index\n",
        "\n",
        "plt.figure(figsize=(8,10)) #making the table a bit bigger so the text is readable\n",
        "plt.barh(index,forest.feature_importances_,height=0.8) #horizontal bar chart\n",
        "plt.ylabel('Feature')\n",
        "plt.yticks(index,predictors) #put the feature names at the y tick marks\n",
        "plt.xlabel(\"Random Forest Feature Importance\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8oYvTIf3d6C"
      },
      "source": [
        "#This function just loops through a series of n_estimator values, builds a different model\n",
        "#for each, and then plots their respective accuracies. By making it a function, it's easier\n",
        "#to try out different ranges of numbers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def tune_number_of_trees(n_estimator_values):\n",
        "    rf_accuracies = []\n",
        "\n",
        "    for n in n_estimator_values:\n",
        "\n",
        "        curr_rf = RandomForestClassifier(n_estimators=n, random_state=41)\n",
        "        curr_rf.fit(train_data,train_sln)\n",
        "        curr_predictions = curr_rf.predict(test_data)\n",
        "        curr_accuracy = metrics.accuracy_score(test_sln,curr_predictions)\n",
        "        rf_accuracies.append(curr_accuracy)\n",
        "\n",
        "\n",
        "    plt.suptitle('Random Forest accuracy vs. number of trees',fontsize=18)\n",
        "    plt.xlabel('# trees')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.plot(n_estimator_values,rf_accuracies,'ro-')\n",
        "    plt.axis([0,n_estimator_values[-1]+1,.8,1])\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "tune_number_of_trees(range(1,31))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeZbed0331ao"
      },
      "source": [
        "\n",
        "It looks like whether we are using small numbers of trees or large ones, the accuracy stays about the same. It appears at least sometimes that Random Forest doesn't take a lot of tuning of the number of trees.\n",
        "\n",
        "Now let's try tuning the number of features used with each tree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQKvSCMM3vsz"
      },
      "source": [
        "def tune_max_features(max_features_values):\n",
        "    rf_accuracies = []\n",
        "\n",
        "    for m in max_features_values:\n",
        "\n",
        "        curr_rf = RandomForestClassifier(n_estimators=10,max_features=m, random_state=31)\n",
        "        curr_rf.fit(train_data,train_sln)\n",
        "        curr_predictions = curr_rf.predict(test_data)\n",
        "        curr_accuracy = metrics.accuracy_score(test_sln,curr_predictions)\n",
        "        rf_accuracies.append(curr_accuracy)\n",
        "\n",
        "\n",
        "    plt.suptitle('Random Forest accuracy vs. max features',fontsize=18)\n",
        "    plt.xlabel('max features')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.plot(max_features_values,rf_accuracies,'ro-')\n",
        "    plt.axis([0,max_features_values[-1]+1,.8,1])\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "tune_max_features(range(1,11))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHTFIV8W4FE9"
      },
      "source": [
        "Note that the above could be subject to changes based on the initial random_state.\n",
        "\n",
        "For this data, which is apparently very easy to learn on (accuracy is very hight), the number of features used with each tree also didn't matter much when used with an ensemble of 10 trees. This is probably something worth tuning if you have a lot of features, especially if many of them might not be very relevant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbTzYfmxzfXu"
      },
      "source": [
        "# Exercise #1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61wjEQVX4Jya"
      },
      "source": [
        "data= pd.read_csv('/content/drive/MyDrive/CS167/datasets/winequality-white.csv')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bhg_5SYEwgyA"
      },
      "source": [
        "target= 'quality'\n",
        "predictors = data.columns.drop(target)\n",
        "train_data, test_data, train_sln, test_sln = train_test_split(data[predictors], data[target], test_size = 0.2, random_state=41)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bODGcYxfwo3k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3RbXOVmwy_t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}